{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bc834e-c299-43d4-bca7-c997e1a6c89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# def scrape_earnings_calls(url):\n",
    "#     # headers = {'User-Agent': 'Apple info@apple.com'}\n",
    "#     headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}\n",
    "#     response = requests.get(url)\n",
    "#     soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#     print(soup)\n",
    "\n",
    "#     all_content = \"\"\n",
    "#     # for article in soup.find_all('article'):\n",
    "#     #     # print(article)\n",
    "#     #     title = article.find('h1').text.strip()\n",
    "#     #     # print(title)\n",
    "#     #     content = article.find('div', class_='T2G6W').text.strip()\n",
    "#     #     print(content[200:400])\n",
    "#     #     all_content += content\n",
    "    \n",
    "#     return all_content\n",
    "\n",
    "# # url = 'https://seekingalpha.com/article/4666958-meta-platforms-inc-2023-q4-results-earnings-call-presentation'\n",
    "\n",
    "# text = scrape_earnings_calls(url)\n",
    "\n",
    "# # output_file_path = f'Data/Earnings Call/sample.txt'\n",
    "# # with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "# #     f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "efa2e3de-4b97-41e4-a52a-43e5866ff69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "Data successfully written to file.\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "headers = {\n",
    "    \"Accept\":\"application/json, text/plain, */*\",\n",
    "    \"Accept-Encoding\":\"gzip, deflate, br\",\n",
    "    \"Accept-Language\":\"en-US,en;q=0.9\",\n",
    "    \"Origin\":\"https://www.nasdaq.com\",\n",
    "    \"Referer\":\"https://www.nasdaq.com\",\n",
    "    \"User-Agent\":\"Meta\"\n",
    "}\n",
    " \n",
    "url = 'https://api.nasdaq.com/api/calendar/earnings?'\n",
    "payload = {\"date\":\"2024-02-21\"}\n",
    "\n",
    "try:\n",
    "    source = requests.get(url=url, headers=headers, params=payload, verify=True)\n",
    "    source.raise_for_status()\n",
    "    data = source.json()\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    print(f\"HTTP error occurred: {e}\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error during requests to {url}: {e}\") \n",
    "    \n",
    "\n",
    "# data_dict = json.loads(str(data))\n",
    "# pprint(data)\n",
    "print(type(data))\n",
    "\n",
    "new_data = {\n",
    "    'asOf': data['data']['asOf'],\n",
    "    'rows': data['data']['rows']\n",
    "}\n",
    "\n",
    "# Adding headers as separate fields at the root level\n",
    "new_data.update(data['data']['headers'])\n",
    "\n",
    "output_file_path = 'Data/Earnings Call/sample.json'\n",
    "\n",
    "try:\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(new_data, f, ensure_ascii=False, indent=4) \n",
    "    print(\"Data successfully written to file.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while writing to the file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ddfcffd-ff09-4110-90f5-2c54b461993d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html><head></head><body></body></html>\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "def scrape_earnings_calls(url):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')  # For running headless Chrome\n",
    "    options.add_argument('start-maximized')\n",
    "    options.add_argument('disable-infobars')\n",
    "    options.add_argument('--disable-extensions')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-application-cache')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for JavaScript to load\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    print(soup)\n",
    "    driver.quit()\n",
    "\n",
    "    all_content = \"\"\n",
    "    for article in soup.find_all('article'):\n",
    "        title = article.find('h1').text.strip()\n",
    "        content = article.find('div', class_='T2G6W').text.strip()  # Make sure class name is correct\n",
    "        print(content[200:400])\n",
    "        all_content += content\n",
    "    \n",
    "    return all_content\n",
    "\n",
    "# url = 'https://seekingalpha.com/article/4666958-meta-platforms-inc-2023-q4-results-earnings-call-presentation'\n",
    "# url = 'https://www.fool.com/earnings/call-transcripts/2024/04/19/regions-financial-rf-q1-2024-earnings-call-transcr/'\n",
    "url = 'https://www.nasdaq.com/market-activity/stocks/meta/earnings'\n",
    "\n",
    "text = scrape_earnings_calls(url)\n",
    "\n",
    "output_file_path = f'Data/Earnings Call/sample.txt'\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d35e51c9-3c57-4fe7-99da-272e28e926a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Meta Debuts Llama 3, Latest AI Model to Power Chatbots\n",
      "Publish Date: None\n",
      "Content: (Bloomberg) -- Facebook parent company Meta Platforms Inc. debuted a new version of its powerful Llama artificial intelligence model, its latest effort to keep pace with similar technology from companies like OpenAI and Alphabet Inc.’s Google.\n",
      "\n",
      "Most Read from Bloomberg\n",
      "\n",
      "Llama 3, unveiled Thursday, is an upgrade from an AI model that Meta released last summer. Chief Product Officer Chris Cox said that model, Llama 2, has been downloaded 170 million times. Llama 2 was billed as open source, though its license included some restrictions such as requiring companies with more than 700 million users to ask for permission to use it.\n",
      "\n",
      "Meta, the world’s largest social media company, is using Llama 3 to run its own in-app AI assistant, called MetaAI, which exists across several products, including Facebook, WhatsApp and Meta’s Ray-Ban smart glasses. The MetaAI assistant will be updated for users on Thursday as well, the company said.\n",
      "\n",
      "Many major tech companies are racing to develop AI products and services, spending billions on high tech chips and employee resources to develop large language models and other AI-focused products. Meta is using AI to power its content feeds and recommendations, but also to improve ad targeting and its virtual reality headsets.\n",
      "\n",
      "Llama 3 is “industry leading on a number of benchmarks for models of this size,” Cox said. “We’re no longer playing catch-up to have a model that’s best-in-class.”\n",
      "\n",
      "The company is also working on several iterations of Llama 3 that will be rolled out as updates, Cox added.\n",
      "\n",
      "Meta has used AI in its products for years, but has leaned more heavily into the new technology over the past year, with executives emphasizing the benefits in public appearances and interviews. Investors have been optimistic about Meta’s use of AI in its products. The shares gained 2.7% to $507.25 at 1:02 p.m. Thursday in New York and have jumped 43% this year.\n",
      "\n",
      "--With assistance from Rachel Metz.\n",
      "\n",
      "(Corrects the number of downloads in the second paragraph of the story published April 18. An earlier version corrected the use of the AI model in the headline.)\n",
      "\n",
      "Most Read from Bloomberg Businessweek\n",
      "\n",
      "©2024 Bloomberg L.P.\n"
     ]
    }
   ],
   "source": [
    "from newspaper import Article\n",
    "from newspaper import Config\n",
    "\n",
    "def scrape_news_article(url):\n",
    "    user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'\n",
    "    config = Config()\n",
    "    config.browser_user_agent = user_agent\n",
    "    article = Article(url, config=config)\n",
    "    # print(article)\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    \n",
    "    text = \"\"\n",
    "    \n",
    "    text += \"Title:\" + article.title\n",
    "    if article.publish_date:\n",
    "        text += \"\\n\\nPublish Date:\" + str(article.publish_date)\n",
    "    text += \"\\n\\nContent:\" + article.text\n",
    "\n",
    "    print('Title:', article.title)\n",
    "    print('Publish Date:', article.publish_date)\n",
    "    print('Content:', article.text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "url = 'https://finance.yahoo.com/news/meta-debuts-llama-3-latest-160000989.html?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAAB2SAHjFa62wKhzC5BHwQ8gYrddWubMi7B7dWOh7WJgeUxxxb7l_yfnqFgEGFAMlbHt9kOzr3s8v191gAMwfFfO-25EQe_XIZwyGbbOK6rh6byhLbv3gcHLfi4GDCzFBsnb0RAZyVj9Z_7eKbzwKQlVjo8NeVJP0jRd9YB3OyM_X'\n",
    "text = scrape_news_article(url)\n",
    "\n",
    "output_file_path = f'Data/News/sample.txt'\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8c018970-78d0-4113-9eb7-11468803e5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filing Type: 10-K\n",
      "Filing Date: 2024-02-02\n",
      "Filing URL: https://www.sec.gov/Archives/edgar/data/1326801/000132680124000012/0001326801-24-000012-index.htm\n",
      "Filing Type: 10-K\n",
      "Filing Date: 2023-02-02\n",
      "Filing URL: https://www.sec.gov/Archives/edgar/data/1326801/000132680123000013/0001326801-23-000013-index.htm\n",
      "Filing Type: 10-K\n",
      "Filing Date: 2022-02-03\n",
      "Filing URL: https://www.sec.gov/Archives/edgar/data/1326801/000132680122000018/0001326801-22-000018-index.htm\n",
      "Filing Type: 10-K\n",
      "Filing Date: 2021-01-28\n",
      "Filing URL: https://www.sec.gov/Archives/edgar/data/1326801/000132680121000014/0001326801-21-000014-index.htm\n",
      "Filing Type: 10-K\n",
      "Filing Date: 2020-01-30\n",
      "Filing URL: https://www.sec.gov/Archives/edgar/data/1326801/000132680120000013/0001326801-20-000013-index.htm\n",
      "Filing Type: 10-K\n",
      "Filing Date: 2019-01-31\n",
      "Filing URL: https://www.sec.gov/Archives/edgar/data/1326801/000132680119000009/0001326801-19-000009-index.htm\n",
      "Filing Type: 10-K\n",
      "Filing Date: 2018-02-01\n",
      "Filing URL: https://www.sec.gov/Archives/edgar/data/1326801/000132680118000009/0001326801-18-000009-index.htm\n",
      "Filing Type: 10-K\n",
      "Filing Date: 2017-02-03\n",
      "Filing URL: https://www.sec.gov/Archives/edgar/data/1326801/000132680117000007/0001326801-17-000007-index.htm\n",
      "Filing Type: 10-K/A\n",
      "Filing Date: 2016-04-27\n",
      "Filing URL: https://www.sec.gov/Archives/edgar/data/1326801/000132680116000063/0001326801-16-000063-index.htm\n",
      "Filing Type: 10-K\n",
      "Filing Date: 2016-01-28\n",
      "Filing URL: https://www.sec.gov/Archives/edgar/data/1326801/000132680116000043/0001326801-16-000043-index.htm\n",
      "Filing Type: 10-K/A\n",
      "Filing Date: 2015-02-13\n",
      "Filing URL: https://www.sec.gov/Archives/edgar/data/1326801/000132680115000010/0001326801-15-000010-index.htm\n",
      "Filing Type: 10-K\n",
      "Filing Date: 2015-01-29\n",
      "Filing URL: https://www.sec.gov/Archives/edgar/data/1326801/000132680115000006/0001326801-15-000006-index.htm\n",
      "Filing Type: 10-K\n",
      "Filing Date: 2014-01-31\n",
      "Filing URL: https://www.sec.gov/Archives/edgar/data/1326801/000132680114000007/0001326801-14-000007-index.htm\n",
      "Filing Type: 10-K\n",
      "Filing Date: 2013-02-01\n",
      "Filing URL: https://www.sec.gov/Archives/edgar/data/1326801/000132680113000003/0001326801-13-000003-index.htm\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_sec_filings(company_code):\n",
    "    base_url = \"https://www.sec.gov/cgi-bin/browse-edgar\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Apple info@apple.com'  # Replace with your actual company name and contact email\n",
    "    }\n",
    "    params = {\n",
    "        'action': 'getcompany',\n",
    "        'CIK': company_code,\n",
    "        'type': '10-k',\n",
    "        'dateb': '',\n",
    "        'owner': 'exclude',\n",
    "        'start': '0',\n",
    "        'count': '40',\n",
    "        'output': 'xml'\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(base_url, params=params, headers=headers)\n",
    "        response.raise_for_status()  # This will raise an HTTPError if the HTTP request returned an unsuccessful status code\n",
    "        soup = BeautifulSoup(response.content, 'lxml')\n",
    "\n",
    "        for filing in soup.find_all('filing'):\n",
    "            print('Filing Type:', filing.type.text)\n",
    "            print('Filing Date:', filing.datefiled.text)\n",
    "            print('Filing URL:', filing.filinghref.text)\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(\"HTTP Error:\", e)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(\"Error during requests to EDGAR:\", e)\n",
    "\n",
    "cik = '1326801' # Meta Inc.\n",
    "# cik = '0000320193' # Apple Inc.\n",
    "\n",
    "scrape_sec_filings(cik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "50269242-cdb2-4ad2-9922-92330b302c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_page(url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Meta info@meta.com'  # Use a proper user-agent\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()  # Checks if request was successful\n",
    "    return response.text\n",
    "\n",
    "def find_document_link(html_content, doc_type='10-K'):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    table = soup.find_all('table')  # Assuming the document links are in a table\n",
    "    if not table:\n",
    "        return None\n",
    "\n",
    "    # Inspecting rows in the document table to find the 10-K link\n",
    "    for row in table[0].find_all('tr'):\n",
    "        cells = row.find_all('td')\n",
    "        if len(cells) > 2:  # Ensuring there are enough cells to check\n",
    "            document_type = cells[3].get_text().strip()  # Adjusted cell index for document type\n",
    "            if doc_type in document_type:\n",
    "                doc_link = cells[2].find('a')['href']  # Adjusted cell index for the hyperlink\n",
    "                full_link = 'https://www.sec.gov' + doc_link\n",
    "                return full_link\n",
    "    return None\n",
    "\n",
    "def extract_10k_data(doc_url):\n",
    "    page_content = download_page(doc_url)\n",
    "    print(page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e597c2cb-5399-4655-a040-32f932688962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-K document link found: https://www.sec.gov/ix?doc=/Archives/edgar/data/1326801/000132680124000012/meta-20231231.htm\n"
     ]
    }
   ],
   "source": [
    "# index_url = 'https://www.sec.gov/Archives/edgar/data/320193/000032019323000106/0000320193-23-000106-index.htm'\n",
    "index_url = 'https://www.sec.gov/Archives/edgar/data/1326801/000132680124000012/0001326801-24-000012-index.htm'\n",
    "\n",
    "index_page_content = download_page(index_url)\n",
    "document_url = find_document_link(index_page_content)\n",
    "\n",
    "if document_url:\n",
    "    print(\"10-K document link found:\", document_url)\n",
    "else:\n",
    "    print(\"10-K document link not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7ef0ceee-8d13-4598-a666-9a70c782a112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XBRL Viewer Please enable JavaScript to use the EDGAR Inline XBRL Viewer.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def download_and_extract_text(url):\n",
    "    headers = {\n",
    "        'User-Agent': 'CompanyName info@company.com'  # Use a proper user-agent\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()  # Checks if request was successful\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Extract text from the BeautifulSoup object by getting text from each tag\n",
    "    text_content = soup.get_text(separator=' ', strip=True)\n",
    "\n",
    "    # Print the first 2000 characters of the text to check\n",
    "    print(text_content[:2000])\n",
    "\n",
    "# Assuming `document_url` contains the full URL to the 10-K document\n",
    "# document_url = 'https://www.sec.gov' + '/ix?doc=/Archives/edgar/data/320193/000032019323000106/aapl-20230930.htm'\n",
    "download_and_extract_text(document_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c75dc94b-4500-434a-be18-47edaa95f930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/1326801/000132680124000012/meta-20231231_htm.xml\n",
      "Total Assets: 229623000000\n",
      "Total Revenue: Not reported\n",
      "Net Income: 39098000000\n",
      "EPS Basic: 15.19\n",
      "Long-term Debt: 18385000000\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "\n",
    "def parse_xbrl_for_metrics(xbrl_content, metrics):\n",
    "    root = etree.fromstring(xbrl_content)\n",
    "    results = {}\n",
    "    for metric, xpath in metrics.items():\n",
    "        element = root.find(xpath, namespaces=root.nsmap)\n",
    "        results[metric] = element.text if element is not None else 'Not reported'\n",
    "    return results\n",
    "\n",
    "def download_xbrl(url):\n",
    "    headers = {'User-Agent': 'CompanyName info@company.com'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()  # Ensure the request was successful\n",
    "    return response.content\n",
    "\n",
    "metrics_to_extract = {\n",
    "    'Total Assets': './/us-gaap:Assets',\n",
    "    'Total Revenue': './/us-gaap:Revenues',\n",
    "    'Net Income': './/us-gaap:NetIncomeLoss',\n",
    "    'EPS Basic': './/us-gaap:EarningsPerShareBasic',\n",
    "    'Long-term Debt': './/us-gaap:LongTermDebt'\n",
    "}\n",
    "\n",
    "# xbrl_url = 'https://www.sec.gov/Archives/edgar/data/320193/000032019323000106/aapl-20230930_htm.xml' # sample\n",
    "\n",
    "a = 'https://www.sec.gov/'\n",
    "xbrl_url = a + document_url[len(a)+8:-4] + '_htm.xml'\n",
    "# print(xbrl_url)\n",
    "\n",
    "xbrl_content = download_xbrl(xbrl_url)\n",
    "financial_data = parse_xbrl_for_metrics(xbrl_content, metrics_to_extract)\n",
    "\n",
    "for metric, value in financial_data.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130b16f7-f5b9-459c-8e4e-c9542408bf96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
